{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Test Results\n",
    "This notebook details the process of formatting the test responses and presents the results\n",
    "of manual evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge recipe metadata into single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>url</th>\n",
       "      <th>step_instructions</th>\n",
       "      <th>whole_recipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beef Stroganoff</td>\n",
       "      <td>600 g / 1.2 lb   scotch fillet steak / boneles...</td>\n",
       "      <td>Use your fist (or rolling pin or mallet) to fl...</td>\n",
       "      <td>https://www.recipetineats.com/beef-stroganoff/</td>\n",
       "      <td>1. Use your fist (or rolling pin or mallet) to...</td>\n",
       "      <td>Recipe Name: Beef Stroganoff, \\nIngredients: 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Creamy Homemade Baked Mac and Cheese</td>\n",
       "      <td>1 lb. dried elbow pasta, 1/2 cup unsalted butt...</td>\n",
       "      <td>Preheat oven to 325 degrees F and grease a 3 q...</td>\n",
       "      <td>https://www.thechunkychef.com/family-favorite-...</td>\n",
       "      <td>1. Preheat oven to 325 degrees F and grease a ...</td>\n",
       "      <td>Recipe Name: Creamy Homemade Baked Mac and Che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegetarian Butternut Squash Chipotle Chili wit...</td>\n",
       "      <td>2 tablespoons olive oil, 1 medium red onion, c...</td>\n",
       "      <td>In a 4- to 6-quart Dutch oven or stockpot over...</td>\n",
       "      <td>https://cookieandkate.com/butternut-squash-chi...</td>\n",
       "      <td>1. In a 4- to 6-quart Dutch oven or stockpot o...</td>\n",
       "      <td>Recipe Name: Vegetarian Butternut Squash Chipo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Bolognese</td>\n",
       "      <td>1 medium onion, chopped, 1 celery stalk, chopp...</td>\n",
       "      <td>Pulse onion, celery, and carrot in a food proc...</td>\n",
       "      <td>https://www.bonappetit.com/recipe/bas-best-bol...</td>\n",
       "      <td>1. Pulse onion, celery, and carrot in a food p...</td>\n",
       "      <td>Recipe Name: Best Bolognese, \\nIngredients: 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Easy Brown Rice Risotto with Mushrooms and Fre...</td>\n",
       "      <td>3 tablespoons olive oil, divided, 1 small yell...</td>\n",
       "      <td>Make sure your oven rack is in the middle posi...</td>\n",
       "      <td>https://cookieandkate.com/easy-brown-rice-riso...</td>\n",
       "      <td>1. Make sure your oven rack is in the middle p...</td>\n",
       "      <td>Recipe Name: Easy Brown Rice Risotto with Mush...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         recipe_name  \\\n",
       "0                                    Beef Stroganoff   \n",
       "1               Creamy Homemade Baked Mac and Cheese   \n",
       "2  Vegetarian Butternut Squash Chipotle Chili wit...   \n",
       "3                                     Best Bolognese   \n",
       "4  Easy Brown Rice Risotto with Mushrooms and Fre...   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  600 g / 1.2 lb   scotch fillet steak / boneles...   \n",
       "1  1 lb. dried elbow pasta, 1/2 cup unsalted butt...   \n",
       "2  2 tablespoons olive oil, 1 medium red onion, c...   \n",
       "3  1 medium onion, chopped, 1 celery stalk, chopp...   \n",
       "4  3 tablespoons olive oil, divided, 1 small yell...   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  Use your fist (or rolling pin or mallet) to fl...   \n",
       "1  Preheat oven to 325 degrees F and grease a 3 q...   \n",
       "2  In a 4- to 6-quart Dutch oven or stockpot over...   \n",
       "3  Pulse onion, celery, and carrot in a food proc...   \n",
       "4  Make sure your oven rack is in the middle posi...   \n",
       "\n",
       "                                                 url  \\\n",
       "0     https://www.recipetineats.com/beef-stroganoff/   \n",
       "1  https://www.thechunkychef.com/family-favorite-...   \n",
       "2  https://cookieandkate.com/butternut-squash-chi...   \n",
       "3  https://www.bonappetit.com/recipe/bas-best-bol...   \n",
       "4  https://cookieandkate.com/easy-brown-rice-riso...   \n",
       "\n",
       "                                   step_instructions  \\\n",
       "0  1. Use your fist (or rolling pin or mallet) to...   \n",
       "1  1. Preheat oven to 325 degrees F and grease a ...   \n",
       "2  1. In a 4- to 6-quart Dutch oven or stockpot o...   \n",
       "3  1. Pulse onion, celery, and carrot in a food p...   \n",
       "4  1. Make sure your oven rack is in the middle p...   \n",
       "\n",
       "                                        whole_recipe  \n",
       "0  Recipe Name: Beef Stroganoff, \\nIngredients: 6...  \n",
       "1  Recipe Name: Creamy Homemade Baked Mac and Che...  \n",
       "2  Recipe Name: Vegetarian Butternut Squash Chipo...  \n",
       "3  Recipe Name: Best Bolognese, \\nIngredients: 1 ...  \n",
       "4  Recipe Name: Easy Brown Rice Risotto with Mush...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = \"../datasets/llm_test_cases/Test Cases.xlsx\"\n",
    "df = pd.read_excel(fpath)\n",
    "\n",
    "schema = \".recipe_name, .ingredients, [.instructions[].text], .source_url\"\n",
    "columns = [\"recipe_name\", \"ingredients\", \"instructions\", \"url\"]\n",
    "fpath = [\"../datasets/llm_test_cases/test_recipes.jl\"]\n",
    "outpath = [\"../datasets/llm_test_cases/test_recipes_cleaned.jsonl\"]\n",
    "\n",
    "cleaned_df = pd.read_json(outpath[0],lines=True)\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_recipe = df.merge(cleaned_df, left_on='start_url', right_on='url')\n",
    "merge_recipe = merge_recipe.merge(cleaned_df, left_on='end_url', right_on='url', suffixes=('_start', '_end'))\n",
    "merge_recipe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results for later\n",
    "merge_recipe.to_excel('../datasets/llm_test_cases/test_recipes.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write responses to spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_name</th>\n",
       "      <th>end_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classic Risotto</td>\n",
       "      <td>Easy Brown Rice Risotto with Mushrooms and Fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Easy Brown Rice Risotto with Mushrooms and Fre...</td>\n",
       "      <td>Classic Risotto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chipotle Chili</td>\n",
       "      <td>Butternut Squash Chipotle Chili with Avocado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Butternut Squash Chipotle Chili with Avocado</td>\n",
       "      <td>Chipotle Chili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beef Stroganoff</td>\n",
       "      <td>Portobello Mushroom Stroganoff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          start_name  \\\n",
       "0                                    Classic Risotto   \n",
       "1  Easy Brown Rice Risotto with Mushrooms and Fre...   \n",
       "2                                     Chipotle Chili   \n",
       "3       Butternut Squash Chipotle Chili with Avocado   \n",
       "4                                    Beef Stroganoff   \n",
       "\n",
       "                                            end_name  \n",
       "0  Easy Brown Rice Risotto with Mushrooms and Fre...  \n",
       "1                                    Classic Risotto  \n",
       "2       Butternut Squash Chipotle Chili with Avocado  \n",
       "3                                     Chipotle Chili  \n",
       "4                     Portobello Mushroom Stroganoff  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_targets = merge_recipe[['start_name','end_name']].copy()\n",
    "recipe_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evaluation_df(fpath):\n",
    "    test_df = pd.read_json(fpath, lines=True)\n",
    "    return recipe_targets.merge(test_df, left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_spreadsheet():\n",
    "    test_results_paths = {'llama': '../datasets/llm_test_cases/test_cases_llama_v2.jsonl',\n",
    "                        'gpt4.5':'../datasets/llm_test_cases/test_cases_gpt4turbo_v2.jsonl',\n",
    "                        'gpt3.5':'../datasets/llm_test_cases/test_cases_gpt3-5_turbo_v2.jsonl',}\n",
    "    test_results = dict()\n",
    "    with pd.ExcelWriter('../datasets/llm_test_cases/test_evaluation_v3.xlsx') as test_writer:\n",
    "        for model_name, result_path in test_results_paths.items():\n",
    "            eval_df = create_evaluation_df(result_path)\n",
    "            test_results[model_name] = eval_df\n",
    "            eval_df.to_excel(test_writer,sheet_name=model_name)\n",
    "# test_results = create_results_spreadsheet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Summary\n",
    "Each test will contain the same type of task: to replace one ingredient from a recipe with another ingredient to create a new recipe as the output. Every test will also have a pair of recipes and a pair of ingredients. In the case of the recipes, one recipe represents the starting recipe and another represents the target recipe. The pair of ingredients details the requested substitution for the test. Information from the starting recipe and the substitution is provided to the language model, while information about the intended target is preserved for test evaluation later and is excluded from the prompt context.\n",
    "\n",
    "Refer to *execute_test_cases.ipynb* for more details on model tests.\n",
    "\n",
    "Models Used:\n",
    "1. [LLaMa-2 (13B) conversational chat model](https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ)\n",
    "2. [OpenAI GPT4-turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)\n",
    "3. [OpenAI GPT3.5-turbo](https://platform.openai.com/docs/models/gpt-3-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Scores\n",
    "\n",
    "Each response to a recipe was scored based on four categories on a pass/fail basis.\n",
    "\n",
    "1. Formatting: Response contains answer in the form of a recipe (Recipe name, followed by ingredients, then followed by instructions)\n",
    "2. Replaced Ingredient: Response makes requested substitutions with appropriate replacements and amounts.\n",
    "3. Customized Instructions: Response tries to implement requested customizations in instructions for preparing the recipe.\n",
    "Accurate instructions are not required for a passing score in this category but are evaluated in the next category.\n",
    "4. Cooking Understanding: Response demonstrates an understanding of cooking; i.e. the response does not contain nonsensical or impossible instructions,\n",
    "nor does it simply copy the instructions from the provided recipe.\n",
    "\n",
    "In addition, the multiple inference task for each test was also scored on the generated name for the new recipe. <br>\n",
    "\n",
    "5. Naming: Generated name appropriately describes the results of the substitution task.\n",
    "\n",
    "<br>\n",
    "Scores are aggregated into an accuracy metric representing the proportion \n",
    "of the 20 test cases passed in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the imported dataframe\n",
    "def format_scores(score_df:pd.DataFrame):\n",
    "    formatted_df = score_df.copy()\n",
    "    formatted_df.drop(columns=['Note'], inplace=True)\n",
    "    formatted_df['Index'] = formatted_df['Index'].ffill(axis=0).astype(int)\n",
    "    formatted_df.dropna(how='all', subset=['Formatting','Replaced Ingredient','Customized Instructions','Cooking Understanding'], inplace=True)\n",
    "    formatted_df.set_index(['Index','Prompt Type'], inplace=True)\n",
    "\n",
    "    return formatted_df\n",
    "    \n",
    "# Load scores from spreadsheets\n",
    "# Reorganize into multiindex dataframe\n",
    "def load_scores(fpath):\n",
    "    sheet_names = ['llama','gpt4.5','gpt3.5']\n",
    "    score_sheets = dict()\n",
    "    for name in sheet_names:\n",
    "        score_sheets[name] = format_scores(pd.read_excel(fpath,sheet_name=name))\\\n",
    "                                            .groupby(by='Prompt Type')\\\n",
    "                                            .mean()\n",
    "    return pd.concat(score_sheets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_scores = load_scores('../datasets/llm_test_cases/evaluation_scores.xlsx')\n",
    "v2_scores = load_scores('../datasets/llm_test_cases/evaluation_scores_v2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Formatting</th>\n",
       "      <th>Replaced Ingredient</th>\n",
       "      <th>Customized Instructions</th>\n",
       "      <th>Cooking Understanding</th>\n",
       "      <th>Naming</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Prompt Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">llama</th>\n",
       "      <th>RAG</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">gpt4.5</th>\n",
       "      <th>RAG</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">gpt3.5</th>\n",
       "      <th>RAG</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Formatting  Replaced Ingredient  Customized Instructions  \\\n",
       "       Prompt Type                                                             \n",
       "llama  RAG                1.00                 0.60                     0.55   \n",
       "       base               1.00                 0.60                     0.55   \n",
       "       multi              1.00                 0.75                     0.70   \n",
       "gpt4.5 RAG                1.00                 0.80                     0.80   \n",
       "       base               1.00                 0.95                     0.95   \n",
       "       multi              1.00                 1.00                     1.00   \n",
       "gpt3.5 RAG                1.00                 0.65                     0.65   \n",
       "       base               1.00                 0.80                     0.80   \n",
       "       multi              0.95                 0.95                     0.90   \n",
       "\n",
       "                    Cooking Understanding  Naming  \n",
       "       Prompt Type                                 \n",
       "llama  RAG                           0.55     NaN  \n",
       "       base                          0.40     NaN  \n",
       "       multi                         0.50    0.90  \n",
       "gpt4.5 RAG                           0.80     NaN  \n",
       "       base                          0.95     NaN  \n",
       "       multi                         1.00    1.00  \n",
       "gpt3.5 RAG                           0.65     NaN  \n",
       "       base                          0.80     NaN  \n",
       "       multi                         0.95    0.95  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining input prompts\n",
    "After reviewing the previous test results, several issues were noted in the input prompts used\n",
    "to generate the responses. The task description was found to be too vague to describe the task to the LLM. \n",
    "The direction of substitution was the problem; was the task to replace ingredient *x* with a new ingredient *y*, or the other way around? \n",
    "Often, the LLM would produce a response where it had interpreted the replacement task opposite of the intended substitution. \n",
    "To fix this problem, the phrase \"substitute *x* for *y*\" was substituted with \n",
    "\"replace ingredient *x* from the original recipe with ingredient *y*\".<br>\n",
    "\n",
    "Additionally, the chain-of-thought prompt specialized too heavily into making a recipe vegetarian, \n",
    "which had a negative impact on response generation for ingredient substitutions that did not \n",
    "expect a vegetarian recipe as the end result. This was remedied by replacing the example with another that simply showed how to reason through substituting ingredients in a recipe without catering to dietary restrictions. <br>\n",
    "\n",
    "The results from responses for tasks with vegetarian substitutions did indicate that having several specialized examples may provoke higher-quality\n",
    "responses, albeit at the loss of flexibility to accurately generate answers for other substitution types.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models were reevaluated using the test corpus. The changes made to the input prompts produced a\n",
    "significant increase in pass rate among the four categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Formatting</th>\n",
       "      <th>Replaced Ingredient</th>\n",
       "      <th>Customized Instructions</th>\n",
       "      <th>Cooking Understanding</th>\n",
       "      <th>Naming</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Prompt Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">llama</th>\n",
       "      <th>COT</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAG</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gpt4.5</th>\n",
       "      <th>COT</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAG</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gpt3.5</th>\n",
       "      <th>COT</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAG</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Formatting  Replaced Ingredient  Customized Instructions  \\\n",
       "       Prompt Type                                                             \n",
       "llama  COT                1.00                 0.95                     0.95   \n",
       "       RAG                1.00                 1.00                     1.00   \n",
       "       base               0.95                 0.95                     0.95   \n",
       "       multi              1.00                 0.90                     0.85   \n",
       "gpt4.5 COT                1.00                 1.00                     1.00   \n",
       "       RAG                1.00                 1.00                     1.00   \n",
       "       base               1.00                 1.00                     1.00   \n",
       "       multi              1.00                 1.00                     1.00   \n",
       "gpt3.5 COT                1.00                 0.95                     0.90   \n",
       "       RAG                1.00                 1.00                     1.00   \n",
       "       base               1.00                 1.00                     1.00   \n",
       "       multi              1.00                 0.95                     0.95   \n",
       "\n",
       "                    Cooking Understanding  Naming  \n",
       "       Prompt Type                                 \n",
       "llama  COT                           0.90     NaN  \n",
       "       RAG                           0.90     NaN  \n",
       "       base                          0.80     NaN  \n",
       "       multi                         0.45    1.00  \n",
       "gpt4.5 COT                           1.00     NaN  \n",
       "       RAG                           1.00     NaN  \n",
       "       base                          1.00     NaN  \n",
       "       multi                         1.00    1.00  \n",
       "gpt3.5 COT                           0.90     NaN  \n",
       "       RAG                           0.95     NaN  \n",
       "       base                          1.00     NaN  \n",
       "       multi                         0.95    0.95  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes and Observations\n",
    "- GPT4-turbo produced high-quality responses regardless of prompt type. As a result, most of the following observations were noted with respect to the less complex models, namely LLaMa-2 and GPT3.5-turbo.\n",
    "\n",
    "- Retrieval-augmented generation appeared to benefit creativity and breadth of knowledge in the generated responses.\n",
    "Uncommon substitution tasks that the models failed in the naive and chain-of-thought case were passed when using RAG. This indicates that language models\n",
    "are able to infer and gather information from the retrieved documents and apply it to the task. In addition, the additional context helped the models in adapting the instructions to match the requested substitutions in the recipe ingredients. A pattern was noticed with LLaMa-2 where the instructions for the output recipe would be too similar to the input recipe. This often led to the listing of inappropriate instructions, such as shredding pork before cooking it in the oven to make pulled pork. Providing an example recipe of a pulled pork sandwich allowed the model to move the shredding process to after the cooking steps. Some nuances of preparing ingredients that eluded the LLM in the base prompt were captured when context recipes were provided. When replacing butternut squash with ground beef, additional context was needed to indicate to the LLM that the ground beef should be browned and steps would be needed to handle the rendered fat, which would not be present in the original recipe using butternut squash.\n",
    "- The downsides of providing more than one recipe as additional context for RAG outweighs the benefit of extra information for two reasons. First, each additional recipe incurs a cost in the input prompt's token length, which in turn leads to significantly longer generation times. In the case of LLaMa-2, the token length exceeded the maximum token length, so the model failed to generate a proper response. Second, the extra text from the additional recipes would \"dilute\" the information from the task description and the original recipe. This led to responses where the output recipe would simply reuse instructions from the context recipes without consideration for the ingredients involved. This was evident in the multiple inference outputs generated by LLaMa-2. While the excessive token lengths led to longer generation times in GPT4 and GPT3.5, they did not encounter the instruction reuse. This was probably because of their longer maximum token lengths.\n",
    "- COT helps with stability of answers. Showing the LLM an example in context strongly influenced the generation to follow the formatting in the example. This assisted in getting a consistent response from the LLM. This also means that formatting in COT examples is much more vital compared to prompts utilizing other techniques when a specific sentence structure is expected in the output. For example, the worked examples used in the first iteration used a different spacing format to separate the recipe name, ingredients, and instructions. Despite containing the same structure of information, the LLM would use the spacing format in the example instead, which made it difficult to read the responses during manual evaluation.\n",
    "- Wei et al.<sup>1</sup> notes that larger models benefit more from chain-of-thought prompting. This matches with the difference in the effect of COT prompts in GPT4.5 compared to LLAMA-2 (13B) and GPT3.5.\n",
    "- Although LLaMa-2 performed poorly in this benchmark compared to GPT4 and GPT3.5, it is important to note that the size of the model was severely restricted due to hardware limitations, whereas the GPT models did not have the same restrictions. The LLaMa-2 model parameter count was only 13 billion and the parameters were quantized into 4 bits with a large quantization group size (128) to further reduce GPU memory requirements. Without these adjustments, the model would have been too expensive to run on a single GPU.\n",
    "\n",
    "<sup>1</sup>[Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerations for Deployment\n",
    "- When considering how user inputs could be fed into the input prompt, strict controls over the range of input formats is a good idea for deployment; specifying queries is non-trivial and can produce significant variance in responses.\n",
    "\n",
    "- Utilizing retrieval-augmentation imposes a large memory requirement to load the embeddings model and the database index into memory. Additionally, performing similarity search will require a meaningful amount of computation time. This will need to be considered when designing around API latencies and hardware costs.\n",
    "- GPT3.5 seems to be a good candidate for implementing into a LLM-backed application, as it strikes a balance between response quality and API costs.\n",
    "- While the operating costs of using the OpenAI API for LLM inference is minimal for a small application, the cost of using the API would probably outscale the initial costs of hosting a model of similar complexity on local hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Prompt engineering using retrieval-augmentation and chain-of-thought prompting proved to be effective in improving the quality of responses for the task of modifying recipes to substitute ingredients. LLaMa-2 (13B) struggled to provide good responses for multiple inference prompts, likely because of token limits, but demonstrated that locally-hosted, smaller models could still provide quality results. As expected, GPT4-turbo excelled at this task and was clearly the best model out of the three. GPT3.5 proved to be a cost-effective alternative to GPT4/GPT4-turbo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-update",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
